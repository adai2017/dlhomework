{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep learning from scratch: homework 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General instructions\n",
    "\n",
    "Complete the exericse listed below in this Jupyter notebook - leaving all of your code in Python cells in the notebook itself.  Feel free to add any necessary cells.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### When submitting this homework:\n",
    "\n",
    "**Make sure you have put your name at the top of each file**\n",
    "    \n",
    "**Make sure all output is present in your notebook prior to submission**\n",
    "\n",
    "**If possible please do not zip your files when uploading to canvas**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import our custom deep learning library\n",
    "\n",
    "Throughout this homework we make use of version 1.0 of our deep learning library you saw previously in class. Activate the Python cell below to import all the necessary files/libraries to complete this homework. It's good to review the description and examples in ```lib_v1_scratchpad``` before moving forward.    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import custom library\n",
    "from deeplearning_library_v1 import superlearn_setup\n",
    "from deeplearning_library_v1 import unsuperlearn_setup\n",
    "\n",
    "# define path to datasets\n",
    "datapath = 'datasets/'\n",
    "\n",
    "# import autograd functionality to bulid function's properly for optimizers\n",
    "import autograd.numpy as np\n",
    "\n",
    "# plotting utilities\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import gridspec\n",
    "\n",
    "# this is needed to compensate for %matplotlib notebook's tendancy to blow up images when plotted inline\n",
    "%matplotlib notebook\n",
    "from matplotlib import rcParams\n",
    "rcParams['figure.autolayout'] = True\n",
    "\n",
    "# automatically refresh if anything has changed in a backend file\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style=\"color:#a50e3e;\">Exercise 1. </span> Normalized gradient descent "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this Exercise you use the *normalized gradient descent* algorithm detailed and implemented in [Section 13.3.1 of the course notes](https://jermwatt.github.io/mlrefined/blog_posts/13_Multilayer_perceptrons/13_3_Normalized_gradient_descent.html) to perform multiclass classification on a preprocessed subset of $10,000$ images from the [MNIST handwritten digit dataset](https://en.wikipedia.org/wiki/MNIST_database), which is located in the ```datasets``` folder and called ``mnist_contrast_normalized.csv``."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, load in the dataset by activating the Python cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = np.loadtxt(datapath + 'mnist_test_contrast_normalized.csv', delimiter = ',')\n",
    "x = data[:,:-1].T\n",
    "y = data[:,-1:].T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, create an instance of the supervised learning wrapper, called ```demo```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "demo = superlearn_setup.Setup(x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You now choose a feature transformation scheme for this task. For this Exercise, choose a 3-layer multi-layer perceptron with ReLU activation, having $30$, $20$, and $10$ units in its first, second, and third layer, respectively. Note that the dimension of the input layer is, as always, determined by the input dimension of $x$, and that of the output layer by the number of classes in the data.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# YOUR CODE GOES HERE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also make sure to use standard normalization along with the multiclass softmax cost to perform this Exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# YOUR CODE GOES HERE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, run normalized gradient descent for a maximum of $500$ iterations, and a fixed steplength of $10^{-1}$ by activating the Python cell below. Notice, the ```fit``` method below takes in an argument called ```version``` indicating whether we want to take normalized gradient descent steps (or not). The ```fit``` method provided for you comes without this optional argument, so you'd have to add it yourself. Additionally, you should use the *normalized gradient descent* algorithm in [Section 13.3.1 of the course notes](https://jermwatt.github.io/mlrefined/blog_posts/13_Multilayer_perceptrons/13_3_Normalized_gradient_descent.html) to modify the gradient descent optimizer in ```optimizers.py``` so that it accepts ```version``` as an input argument, and runs normalized gradient descent when ```version``` is set to 'normalized'.       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "demo.fit(max_its = 500, alpha_choice = 10**(-1), version='normalized')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, plot the per-iteration cost function evaluation as well as number of misclassifications by simply activating the Python cell below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "demo.show_histories(start = 10, labels=['normalized run'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should produce a figure like the one shown below.   \n",
    "<figure><img src=\"Ex1.png\"></figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style=\"color:#a50e3e;\">Exercise 2. </span> Momentum trick"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this Exercise, you'll modify the gradient descent optimizer again, this time to add a new argument called ```beta``` that stores the the momentum parameter, as discussed in detail in [Section 13.4 of the course notes](https://jermwatt.github.io/mlrefined/blog_posts/13_Multilayer_perceptrons/13_4_Momentum_trick.html).\n",
    "\n",
    "T complete this Exercise you should use the same dataset, network architecture, normalization scheme, cost function, steplength, and maximum iteration count as Exercise 1, run normalized gradient descent for three values of beta ($\\beta=0$, $\\beta=.2$, and $\\beta=.9$), and plot the cost/misclassification histories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# YOUR CODE GOES HERE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should produce a figure like the one shown below.   \n",
    "<figure><img src=\"Ex2.png\"></figure>"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "30px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": false,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 1,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
